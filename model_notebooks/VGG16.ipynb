{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akq47pDA-O2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "66117504-2cb4-414c-a305-38a2fe292e85"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0gV5j13-SbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d53f269-d63a-466a-9b3f-004c7cb89ca6"
      },
      "source": [
        "%cd /content/drive/My Drive/xview\n",
        "!pip install numpy tensorflow-gpu\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/xview\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bf/c28971266ca854a64f4b26f07c4112ddd61f30b4d1f18108b954a746f8ea/tensorflow_gpu-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.30.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (49.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.2.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (4.41.1)\n",
            "Collecting libtiff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/8f/b844284d43d385c08967b25eb76f625a5f06490cc4680e17644587053756/libtiff-0.4.2.tar.gz (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (7.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 21)) (0.16.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 22)) (4.1.2.30)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 23)) (0.2.9)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 24)) (5.5.0)\n",
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a4/e66aafbefcbb717813bf3a355c8c4fc3ed04ea1dd7feb2920f2f4f868921/geopandas-0.8.1-py2.py3-none-any.whl (962kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 26)) (2.3.1)\n",
            "Collecting imantics\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/ff/8f92fa03b42f14860bc882d08187b359d3b8f9ef670d4efbed090d451c58/imantics-0.1.12.tar.gz\n",
            "Collecting simplification\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/7f/a174c2e069a8626b2f4ba2014ae83e594e7c95bcf694c8dac334af604772/simplification-0.5.1-cp36-cp36m-manylinux2010_x86_64.whl (610kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 21.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 29)) (0.22.2.post1)\n",
            "Requirement already satisfied: chainer in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 30)) (7.4.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 31)) (2.2.2)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 16)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 16)) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 16)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 16)) (2.4.7)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 21)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 21)) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 21)) (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements.txt (line 23)) (1.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements.txt (line 23)) (1.15.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->-r requirements.txt (line 24)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->-r requirements.txt (line 24)) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->-r requirements.txt (line 24)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->-r requirements.txt (line 24)) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->-r requirements.txt (line 24)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->-r requirements.txt (line 24)) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->-r requirements.txt (line 24)) (4.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->-r requirements.txt (line 24)) (49.1.0)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas->-r requirements.txt (line 25)) (1.0.5)\n",
            "Collecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c3/071e080230ac4b6c64f1a2e2f9161c9737a2bc7b683d2c90b024825000c0/pyproj-2.6.1.post1-cp36-cp36m-manylinux2010_x86_64.whl (10.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9MB 33.4MB/s \n",
            "\u001b[?25hCollecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/20/4e63bc5c6e62df889297b382c3ccd4a7a488b00946aaaf81a118158c6f09/Fiona-1.8.13.post1-cp36-cp36m-manylinux1_x86_64.whl (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 210kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 26)) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 26)) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 26)) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 26)) (1.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from imantics->-r requirements.txt (line 27)) (4.2.6)\n",
            "Collecting xmljson\n",
            "  Downloading https://files.pythonhosted.org/packages/91/2d/7191efe15406b8b99e2b5905ca676a8a3dc2936416ade7ed17752902c250/xmljson-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 29)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from chainer->-r requirements.txt (line 30)) (3.7.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer->-r requirements.txt (line 30)) (3.0.12)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer->-r requirements.txt (line 30)) (3.12.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (0.34.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (1.30.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 31)) (2.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->-r requirements.txt (line 24)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->-r requirements.txt (line 24)) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->-r requirements.txt (line 24)) (0.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas->-r requirements.txt (line 25)) (2018.9)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas->-r requirements.txt (line 25)) (19.3.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas->-r requirements.txt (line 25)) (7.1.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 31)) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 31)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 31)) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 31)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 31)) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 31)) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 31)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 31)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 31)) (2.10)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 31)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 31)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 31)) (3.1.0)\n",
            "Building wheels for collected packages: libtiff, imantics\n",
            "  Building wheel for libtiff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libtiff: filename=libtiff-0.4.2-cp36-cp36m-linux_x86_64.whl size=280205 sha256=1d28dce62e57c56b387f2dd6a8ab07633f32a98643dbcdd2b21c56900cf6d9fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/ce/79/9c7115224f798f73bdbd2c23e06c6fa048adcca7041b9fd104\n",
            "  Building wheel for imantics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imantics: filename=imantics-0.1.12-cp36-none-any.whl size=16034 sha256=ab6d69bf9f7792f79a9803183b12ccedb88317d72eed8ad35da3608659124bc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/93/1c/9e2fc52eb74441941bc76cac441ddcc2c7ad67b18e1849e62a\n",
            "Successfully built libtiff imantics\n",
            "Installing collected packages: libtiff, pyproj, munch, cligj, click-plugins, fiona, geopandas, xmljson, imantics, simplification, tensorboardX\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.5.0 fiona-1.8.13.post1 geopandas-0.8.1 imantics-0.1.12 libtiff-0.4.2 munch-2.5.0 pyproj-2.6.1.post1 simplification-0.5.1 tensorboardX-2.1 xmljson-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZc-0-Z7-XAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "ae5777b8-aad4-4093-d0e7-fbf03c88dab9"
      },
      "source": [
        "#!pip list\n",
        "#!pip uninstall cupy\n",
        "!pip uninstall cupy-cuda101\n",
        "!pip install 'cupy>=7.4.0,<8.0.0'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling cupy-cuda101-7.4.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/cupy/*\n",
            "    /usr/local/lib/python3.6/dist-packages/cupy_cuda101-7.4.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/cupyx/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled cupy-cuda101-7.4.0\n",
            "Collecting cupy<8.0.0,>=7.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/6f/73b6509b2fd1068fad989a11aaa0ce01dbd6a6101b423c03ee264838ec74/cupy-7.6.0.tar.gz (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy<8.0.0,>=7.4.0) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy<8.0.0,>=7.4.0) (1.15.0)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy<8.0.0,>=7.4.0) (0.5)\n",
            "Building wheels for collected packages: cupy\n",
            "  Building wheel for cupy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cupy: filename=cupy-7.6.0-cp36-cp36m-linux_x86_64.whl size=32978683 sha256=59e7f195042257f1c78251045e2c4f3014e8e9523708ba45b8441811d502e21d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/33/12/9e457ba44352ffe2a614f7f465c0b149ebc61413b0aa7144d6\n",
            "Successfully built cupy\n",
            "Installing collected packages: cupy\n",
            "Successfully installed cupy-7.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPG1RFKn-pWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e959570-06bd-4619-ece4-4e19542d8f35"
      },
      "source": [
        "%cd /content/drive/My Drive/xview/model/\n",
        "%mkdir /content/sample_data/output\n",
        "%mkdir /content/sample_data/output/process_images\n",
        "%mkdir /content/sample_data/output/csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/xview/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvZAtDdu-4Ob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7456abf0-6775-4e4a-a837-b56b4996460f"
      },
      "source": [
        "!python process_data.py --input_dir \"/content/drive/My Drive/xview/xBD\"  --output_dir \"/content/sample_data/output/process_images\" --output_dir_csv \"/content/sample_data/output/csv\" --val_split_pct 0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Started Processing for Data\n",
            "100% 5598/5598 [1:19:41<00:00,  1.17it/s]\n",
            "INFO:root:Finished Processing Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMFoLoOi5hD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16556e15-cadf-41e4-81b2-52d81fcf70e3"
      },
      "source": [
        "from PIL import Image\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import argparse\n",
        "import logging\n",
        "import json\n",
        "import cv2\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import shapely.wkt\n",
        "import shapely\n",
        "from shapely.geometry import Polygon\n",
        "from collections import defaultdict\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import ast\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Add, Input, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF8JH8XB5qVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ordinal_loss(y_true, y_pred):\n",
        "    weights = K.cast(K.abs(K.argmax(y_true, axis=1) - K.argmax(y_pred, axis=1))/(K.int_shape(y_pred)[1] - 1), dtype='float32')\n",
        "    return (1.0 + weights) * keras.losses.categorical_crossentropy(y_true, y_pred )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoJDjINF5v9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_vgg16_model():\n",
        "  weights = 'imagenet'\n",
        "  inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "  base_model = VGG16(include_top=False, weights=weights, input_shape=(128, 128, 3))\n",
        "\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  x = Conv2D(32, (5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=(128, 128, 3))(inputs)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)\n",
        "\n",
        "  x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)\n",
        "\n",
        "  x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  base_resnet = base_model(inputs)\n",
        "  base_resnet = Flatten()(base_resnet)\n",
        "\n",
        "  concated_layers = Concatenate()([x, base_resnet])\n",
        "\n",
        "  concated_layers = Dense(2024, activation='relu')(concated_layers)\n",
        "  concated_layers = Dense(524, activation='relu')(concated_layers)\n",
        "  concated_layers = Dense(124, activation='relu')(concated_layers)\n",
        "  output = Dense(4, activation='relu')(concated_layers)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=output)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLhCrhVv52tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import argparse\n",
        "import logging\n",
        "import json\n",
        "import cv2\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import shapely.wkt\n",
        "import shapely\n",
        "from shapely.geometry import Polygon\n",
        "from collections import defaultdict\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import ast\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Add, Input, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-azISpN6B35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Configurations\n",
        "NUM_WORKERS = 4 \n",
        "NUM_CLASSES = 4\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 40 \n",
        "LEARNING_RATE = 0.0001\n",
        "RANDOM_SEED = 123\n",
        "LOG_STEP = 150\n",
        "LOG_DIR = '/path/to/logs' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "damage_intensity_encoding = dict()\n",
        "damage_intensity_encoding[3] = '3'\n",
        "damage_intensity_encoding[2] = '2' \n",
        "damage_intensity_encoding[1] = '1' \n",
        "damage_intensity_encoding[0] = '0' \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "695zWO4Xc40k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97d5bdb6-e78b-4865-c3eb-91e00aad1456"
      },
      "source": [
        "print(LOG_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/path/to/logs20200727-104256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhh4q2-96FQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrTk58ZN6J3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_generator(test_csv, test_dir):\n",
        "    df = pd.read_csv(test_csv)\n",
        "    df = df.replace({\"labels\" : damage_intensity_encoding })\n",
        "\n",
        "    gen = keras.preprocessing.image.ImageDataGenerator(\n",
        "                             rescale=1/255.)\n",
        "\n",
        "\n",
        "    return gen.flow_from_dataframe(dataframe=df,\n",
        "                                   directory=test_dir,\n",
        "                                   x_col='uuid',\n",
        "                                   y_col='labels',\n",
        "                                   batch_size=BATCH_SIZE,\n",
        "                                   shuffle=False,\n",
        "                                   seed=RANDOM_SEED,\n",
        "                                   class_mode=\"categorical\",\n",
        "                                   target_size=(128, 128))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPeKxY2u6K1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_data(df, in_dir):\n",
        "\n",
        "    df = df.replace({\"labels\" : damage_intensity_encoding })\n",
        "    gen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,\n",
        "                             vertical_flip=True,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             rescale=1/255.)\n",
        "    return gen.flow_from_dataframe(dataframe=df,\n",
        "                                   directory=in_dir,\n",
        "                                   x_col='uuid',\n",
        "                                   y_col='labels',\n",
        "                                   batch_size=BATCH_SIZE,\n",
        "                                   seed=RANDOM_SEED,\n",
        "                                   class_mode=\"categorical\",\n",
        "                                   target_size=(128, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxpj8Vq_6QtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_data, train_csv, test_data, test_csv, model_in, model_out):\n",
        "\n",
        "    model = generate_vgg16_model()\n",
        "\n",
        "    # Add model weights if provided by user\n",
        "    if model_in is not None:\n",
        "        model.load_weights(model_in)\n",
        "\n",
        "    df = pd.read_csv(train_csv)\n",
        "    class_weights = compute_class_weight('balanced', np.unique(df['labels'].to_list()), df['labels'].to_list());\n",
        "    d_class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "    samples = df['uuid'].count()\n",
        "    steps = np.ceil(samples/BATCH_SIZE)\n",
        "\n",
        "    # Augments the training data\n",
        "    train_gen_flow = augment_data(df, train_data)\n",
        "\n",
        "    #Set up tensorboard logging\n",
        "    tensorboard_callbacks = keras.callbacks.TensorBoard(log_dir=LOG_DIR,\n",
        "                                                        batch_size=BATCH_SIZE)\n",
        "\n",
        "    \n",
        "    #Filepath to save model weights\n",
        "    filepath = model_out + \"-saved-model-{epoch:02d}-{accuracy:.2f}.hdf5\"\n",
        "    checkpoints = keras.callbacks.ModelCheckpoint(filepath,\n",
        "                                                    monitor='accuracy',\n",
        "                                                    verbose=1,\n",
        "                                                    mode='max',\n",
        "                                                    save_best_only=True)\n",
        "\n",
        "    #Adds adam optimizer\n",
        "    adam = keras.optimizers.Adam(lr=LEARNING_RATE,\n",
        "                                    beta_1=0.9,\n",
        "                                    beta_2=0.999,\n",
        "                                    decay=0.0,\n",
        "                                    amsgrad=False)\n",
        "\n",
        "\n",
        "    model.compile(loss=ordinal_loss, optimizer=adam, metrics=['accuracy', f1])\n",
        "\n",
        "    #Training begins\n",
        "    model.fit_generator(generator=train_gen_flow,\n",
        "                        steps_per_epoch=steps,\n",
        "                        epochs=NUM_EPOCHS,\n",
        "                        workers=NUM_WORKERS,\n",
        "                        use_multiprocessing=True,\n",
        "                        class_weight=d_class_weights,\n",
        "                        callbacks=[tensorboard_callbacks, checkpoints],\n",
        "                        verbose=1)\n",
        "\n",
        "\n",
        "    #Evalulate f1 weighted scores on validation set\n",
        "    validation_gen = validation_generator(test_csv, test_data)\n",
        "    predictions = model.predict(validation_gen)\n",
        "\n",
        "    val_trues = validation_gen.classes\n",
        "    val_pred = np.argmax(predictions, axis=-1)\n",
        "\t\n",
        "    precision = precision(y_true, y_pred)\n",
        "    print('precision: {}').format(precision)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    print('recall: {}').format(recall)\n",
        "    f1_weighted = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "    \n",
        "    print(f1_weighted)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waFGRdjfyyIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFgQntFDIxay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e364315-d229-4231-8928-74794b701173"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-6a239942-25f1-0e05-b052-64e1d22e6237)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsWg_zFY6Sgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b95bdf12-634a-4999-b262-adfbb9f25784"
      },
      "source": [
        "train_model(\"/content/sample_data/output/process_images\", \"/content/sample_data/output/csv/train.csv\", \"/content/sample_data/output/process_images\", \"/content/sample_data/output/csv/test.csv\", None, \"/content/drive/My Drive/xview/baseline_model/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 3s 0us/step\n",
            "Found 146508 validated image filenames belonging to 4 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v2.py:92: UserWarning: The TensorBoard callback `batch_size` argument (for histogram computation) is deprecated with TensorFlow 2.0. It will be ignored.\n",
            "  warnings.warn('The TensorBoard callback `batch_size` argument '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "2290/2290 [==============================] - 648s 283ms/step - loss: 2.1518 - accuracy: 0.4650 - f1: 0.4132\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.46497, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-01-0.46.hdf5\n",
            "Epoch 2/40\n",
            "2290/2290 [==============================] - 629s 275ms/step - loss: 1.5550 - accuracy: 0.4962 - f1: 0.4159\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.46497 to 0.49615, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-02-0.50.hdf5\n",
            "Epoch 3/40\n",
            "2290/2290 [==============================] - 619s 270ms/step - loss: 1.5798 - accuracy: 0.4636 - f1: 0.4085\n",
            "\n",
            "Epoch 00003: accuracy did not improve from 0.49615\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.46497 to 0.49615, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-02-0.50.hdf5\n",
            "2289/2290 [============================>.] - ETA: 0s - loss: 1.5233 - accuracy: 0.5119 - f1: 0.4098\n",
            "Epoch 00003: accuracy did not improve from 0.49615\n",
            "2290/2290 [==============================] - 628s 274ms/step - loss: 1.5232 - accuracy: 0.5118 - f1: 0.4098\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.49615 to 0.51182, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-04-0.51.hdf5\n",
            "Epoch 5/40\n",
            "2290/2290 [==============================] - 635s 277ms/step - loss: 1.4335 - accuracy: 0.5445 - f1: 0.4116\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.51182 to 0.54450, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-05-0.54.hdf5\n",
            "Epoch 6/40\n",
            "2290/2290 [==============================] - 633s 276ms/step - loss: 1.4594 - accuracy: 0.5462 - f1: 0.4085\n",
            "\n",
            "Epoch 00006: accuracy improved from 0.54450 to 0.54617, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-06-0.55.hdf5\n",
            "Epoch 7/40\n",
            "2290/2290 [==============================] - 633s 276ms/step - loss: 1.4418 - accuracy: 0.5167 - f1: 0.4091\n",
            "\n",
            "Epoch 00007: accuracy did not improve from 0.54617\n",
            "Epoch 8/40\n",
            "2290/2290 [==============================] - 635s 277ms/step - loss: 1.4681 - accuracy: 0.5707 - f1: 0.4092\n",
            "\n",
            "Epoch 00008: accuracy improved from 0.54617 to 0.57065, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-08-0.57.hdf5\n",
            "Epoch 9/40\n",
            "2290/2290 [==============================] - 636s 278ms/step - loss: 1.3547 - accuracy: 0.5712 - f1: 0.4161\n",
            "\n",
            "Epoch 00009: accuracy improved from 0.57065 to 0.57124, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-09-0.57.hdf5\n",
            "\n",
            "Epoch 00008: accuracy improved from 0.54617 to 0.57065, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-08-0.57.hdf5\n",
            "Epoch 10/40\n",
            "2289/2290 [============================>.] - ETA: 0s - loss: 1.3955 - accuracy: 0.5776 - f1: 0.4169\n",
            "Epoch 00009: accuracy improved from 0.57065 to 0.57124, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-09-0.57.hdf5\n",
            "2290/2290 [==============================] - 635s 277ms/step - loss: 1.3953 - accuracy: 0.5776 - f1: 0.4169\n",
            "\n",
            "Epoch 00010: accuracy improved from 0.57124 to 0.57759, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-10-0.58.hdf5\n",
            "Epoch 11/40\n",
            "2290/2290 [==============================] - 640s 280ms/step - loss: 1.4137 - accuracy: 0.5365 - f1: 0.4114\n",
            "\n",
            "Epoch 00011: accuracy did not improve from 0.57759\n",
            "Epoch 12/40\n",
            "2290/2290 [==============================] - 642s 280ms/step - loss: 1.3990 - accuracy: 0.5737 - f1: 0.4103\n",
            "\n",
            "Epoch 00011: accuracy did not improve from 0.57759\n",
            "\n",
            "Epoch 00012: accuracy did not improve from 0.57759\n",
            "Epoch 13/40\n",
            "2289/2290 [============================>.] - ETA: 0s - loss: 1.3761 - accuracy: 0.5623 - f1: 0.4131Epoch 13/40\n",
            "\n",
            "Epoch 00012: accuracy did not improve from 0.57759\n",
            "2290/2290 [==============================] - 647s 282ms/step - loss: 1.3763 - accuracy: 0.5623 - f1: 0.4131\n",
            "\n",
            "Epoch 00013: accuracy did not improve from 0.57759\n",
            "Epoch 14/40\n",
            "2289/2290 [============================>.] - ETA: 0s - loss: 1.5684 - accuracy: 0.5192 - f1: 0.4040\n",
            "\n",
            "Epoch 00013: accuracy did not improve from 0.57759\n",
            "2290/2290 [==============================] - 648s 283ms/step - loss: 1.5686 - accuracy: 0.5192 - f1: 0.4040\n",
            "\n",
            "Epoch 00014: accuracy did not improve from 0.57759\n",
            "Epoch 15/40\n",
            "2290/2290 [==============================] - 642s 280ms/step - loss: 1.3721 - accuracy: 0.5944 - f1: 0.4039\n",
            "\n",
            "Epoch 00015: accuracy improved from 0.57759 to 0.59442, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-15-0.59.hdf5\n",
            "Epoch 16/40\n",
            "2290/2290 [==============================] - 640s 280ms/step - loss: 1.3891 - accuracy: 0.5476 - f1: 0.4077\n",
            "\n",
            "Epoch 00016: accuracy did not improve from 0.59442\n",
            "Epoch 17/40\n",
            "2290/2290 [==============================] - 637s 278ms/step - loss: 1.4156 - accuracy: 0.5506 - f1: 0.4052\n",
            "\n",
            "Epoch 00017: accuracy did not improve from 0.59442\n",
            "Epoch 18/40\n",
            "2290/2290 [==============================] - 635s 277ms/step - loss: 1.3187 - accuracy: 0.6012 - f1: 0.4154\n",
            "\n",
            "Epoch 00018: accuracy improved from 0.59442 to 0.60117, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-18-0.60.hdf5\n",
            "Epoch 19/40\n",
            "2290/2290 [==============================] - 637s 278ms/step - loss: 1.2871 - accuracy: 0.6146 - f1: 0.4140\n",
            "\n",
            "Epoch 00019: accuracy improved from 0.60117 to 0.61456, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-19-0.61.hdf5\n",
            "Epoch 20/40\n",
            "2289/2290 [============================>.] - ETA: 0s - loss: 1.2816 - accuracy: 0.6135 - f1: 0.4173\n",
            "Epoch 00019: accuracy improved from 0.60117 to 0.61456, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-19-0.61.hdf5\n",
            "2290/2290 [==============================] - 641s 280ms/step - loss: 1.2818 - accuracy: 0.6134 - f1: 0.4173\n",
            "\n",
            "Epoch 00020: accuracy did not improve from 0.61456\n",
            "Epoch 21/40\n",
            "2289/2290 [============================>.] - ETA: 0s - loss: 1.3030 - accuracy: 0.6027 - f1: 0.4188\n",
            "Epoch 00020: accuracy did not improve from 0.61456\n",
            "2290/2290 [==============================] - 646s 282ms/step - loss: 1.3029 - accuracy: 0.6027 - f1: 0.4188\n",
            "\n",
            "Epoch 00021: accuracy did not improve from 0.61456\n",
            "Epoch 22/40\n",
            "2290/2290 [==============================] - 649s 283ms/step - loss: 1.3021 - accuracy: 0.6012 - f1: 0.4086\n",
            "\n",
            "Epoch 00022: accuracy did not improve from 0.61456\n",
            "Epoch 23/40\n",
            "2290/2290 [==============================] - 650s 284ms/step - loss: 1.2372 - accuracy: 0.6251 - f1: 0.4093\n",
            "\n",
            "Epoch 00023: accuracy improved from 0.61456 to 0.62514, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-23-0.63.hdf5\n",
            "Epoch 24/40\n",
            "2290/2290 [==============================] - 645s 282ms/step - loss: 1.2368 - accuracy: 0.6270 - f1: 0.4085\n",
            "\n",
            "Epoch 00024: accuracy improved from 0.62514 to 0.62696, saving model to /content/drive/My Drive/xview/baseline_model/-saved-model-24-0.63.hdf5\n",
            "Epoch 25/40\n",
            " 235/2290 [==>...........................] - ETA: 9:36 - loss: 1.2346 - accuracy: 0.6289 - f1: 0.4037Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsN8K1ZEyOYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}